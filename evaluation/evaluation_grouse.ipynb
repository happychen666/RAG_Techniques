{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Evaluation and Meta-Evaluation with GroUSE\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial will teach how to evaluate your model of Grounded Question Answering, the common task on the last stage of a RAG pipeline.\n",
    "\n",
    "It will present six metrics that can cover the seven failures modes of Grounded Question Answering.\n",
    "\n",
    "If you want to create your custom evaluator, a second section presents how to evaluate your custom judge LLM on GroUSE unit tests.\n",
    "\n",
    "Check the [GroUSE paper](paper_link.link) for more details.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "<!-- TODO -->\n",
    "\n",
    "## Key Components\n",
    "\n",
    "<!-- TODO -->\n",
    "\n",
    "## Grounded Question Answering\n",
    "\n",
    "<!-- TODO -->\n",
    "\n",
    "## Evaluation Metrics\n",
    "\n",
    "### 1. Answer Relevancy\n",
    "\n",
    "<!-- TODO -->\n",
    "\n",
    "### 2. Completeness\n",
    "\n",
    "<!-- TODO -->\n",
    "\n",
    "### 3. Faithfulness\n",
    "\n",
    "<!-- TODO -->\n",
    "\n",
    "### 4. Usefulness\n",
    "\n",
    "<!-- TODO -->\n",
    "\n",
    "### 5. Positive Acceptance\n",
    "\n",
    "Percentage of samples whose context had information about the answer and were answered by the model.\n",
    "\n",
    "### 6. Negative Rejection\n",
    "\n",
    "Percentage of samples whose context had no information to answer the question and where the model explained that it could not give an answer to the question.\n",
    "\n",
    "## Benefits of the approach\n",
    "\n",
    "<!-- TODO -->\n",
    "\n",
    "## Implementation details\n",
    "\n",
    "<!-- TODO -->\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "<!-- TODO -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- TODO add Mermaid schema -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--> TODO <-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--> TODO <-->"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
