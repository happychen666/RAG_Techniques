{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Indices in Document Retrieval\n",
    "\n",
    "## Overview\n",
    "\n",
    "This code implements a Hierarchical Indexing system for document retrieval, utilizing two levels of encoding: document-level summaries and detailed chunks. This approach aims to improve the efficiency and relevance of information retrieval by first identifying relevant document sections through summaries, then drilling down to specific details within those sections.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Traditional flat indexing methods can struggle with large documents or corpus, potentially missing context or returning irrelevant information. Hierarchical indexing addresses this by creating a two-tier search system, allowing for more efficient and context-aware retrieval.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. PDF processing and text chunking\n",
    "2. Asynchronous document summarization using OpenAI's GPT-4\n",
    "3. Vector store creation for both summaries and detailed chunks using FAISS and OpenAI embeddings\n",
    "4. Custom hierarchical retrieval function\n",
    "\n",
    "## Method Details\n",
    "\n",
    "### Document Preprocessing and Encoding\n",
    "\n",
    "1. The PDF is loaded and split into documents (likely by page).\n",
    "2. Each document is summarized asynchronously using GPT-4.\n",
    "3. The original documents are also split into smaller, detailed chunks.\n",
    "4. Two separate vector stores are created:\n",
    "   - One for document-level summaries\n",
    "   - One for detailed chunks\n",
    "\n",
    "### Asynchronous Processing and Rate Limiting\n",
    "\n",
    "1. The code uses asynchronous programming (asyncio) to improve efficiency.\n",
    "2. Implements batching and exponential backoff to handle API rate limits.\n",
    "\n",
    "### Hierarchical Retrieval\n",
    "\n",
    "The `retrieve_hierarchical` function implements the two-tier search:\n",
    "\n",
    "1. It first searches the summary vector store to identify relevant document sections.\n",
    "2. For each relevant summary, it then searches the detailed chunk vector store, filtering by the corresponding page number.\n",
    "3. This approach ensures that detailed information is retrieved only from the most relevant document sections.\n",
    "\n",
    "## Benefits of this Approach\n",
    "\n",
    "1. Improved Retrieval Efficiency: By first searching summaries, the system can quickly identify relevant document sections without processing all detailed chunks.\n",
    "2. Better Context Preservation: The hierarchical approach helps maintain the broader context of retrieved information.\n",
    "3. Scalability: This method is particularly beneficial for large documents or corpus, where flat searching might be inefficient or miss important context.\n",
    "4. Flexibility: The system allows for adjusting the number of summaries and chunks retrieved, enabling fine-tuning for different use cases.\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "1. Asynchronous Programming: Utilizes Python's asyncio for efficient I/O operations and API calls.\n",
    "2. Rate Limit Handling: Implements batching and exponential backoff to manage API rate limits effectively.\n",
    "3. Persistent Storage: Saves the generated vector stores locally to avoid unnecessary recomputation.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Hierarchical indexing represents a sophisticated approach to document retrieval, particularly suitable for large or complex document sets. By leveraging both high-level summaries and detailed chunks, it offers a balance between broad context understanding and specific information retrieval. This method has potential applications in various fields requiring efficient and context-aware information retrieval, such as legal document analysis, academic research, or large-scale content management systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/hierarchical_indices.svg\" alt=\"hierarchical_indices\" style=\"width:50%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\N7\\PycharmProjects\\llm_tasks\\RAG_TECHNIQUES\\.venv\\Lib\\site-packages\\deepeval\\__init__.py:45: UserWarning: You are using deepeval version 0.21.73, however version 1.0.3 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains.summarize.chain import load_summarize_chain\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define document path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to encode to both summary and chunk levels, sharing the page metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def encode_pdf_hierarchical(path, chunk_size=1000, chunk_overlap=200, is_string=False):\n",
    "    \"\"\"\n",
    "    Asynchronously encodes a PDF book into a hierarchical vector store using OpenAI embeddings.\n",
    "    Includes rate limit handling with exponential backoff.\n",
    "    \n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple containing two FAISS vector stores:\n",
    "        1. Document-level summaries\n",
    "        2. Detailed chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load PDF documents\n",
    "    if not is_string:\n",
    "        loader = PyPDFLoader(path)\n",
    "        documents = await asyncio.to_thread(loader.load)\n",
    "    else:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            # Set a really small chunk size, just to show.\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            length_function=len,\n",
    "            is_separator_regex=False,\n",
    "        )\n",
    "        documents = text_splitter.create_documents([path])\n",
    "\n",
    "\n",
    "    # Create document-level summaries\n",
    "    summary_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\", max_tokens=4000)\n",
    "    summary_chain = load_summarize_chain(summary_llm, chain_type=\"map_reduce\")\n",
    "    \n",
    "    async def summarize_doc(doc):\n",
    "        \"\"\"\n",
    "        Summarizes a single document with rate limit handling.\n",
    "        \n",
    "        Args:\n",
    "            doc: The document to be summarized.\n",
    "            \n",
    "        Returns:\n",
    "            A summarized Document object.\n",
    "        \"\"\"\n",
    "        # Retry the summarization with exponential backoff\n",
    "        summary_output = await retry_with_exponential_backoff(summary_chain.ainvoke([doc]))\n",
    "        summary = summary_output['output_text']\n",
    "        return Document(\n",
    "            page_content=summary,\n",
    "            metadata={\"source\": path, \"page\": doc.metadata[\"page\"], \"summary\": True}\n",
    "        )\n",
    "\n",
    "    # Process documents in smaller batches to avoid rate limits\n",
    "    batch_size = 5  # Adjust this based on your rate limits\n",
    "    summaries = []\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        batch = documents[i:i+batch_size]\n",
    "        batch_summaries = await asyncio.gather(*[summarize_doc(doc) for doc in batch])\n",
    "        summaries.extend(batch_summaries)\n",
    "        await asyncio.sleep(1)  # Short pause between batches\n",
    "\n",
    "    # Split documents into detailed chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    detailed_chunks = await asyncio.to_thread(text_splitter.split_documents, documents)\n",
    "\n",
    "    # Update metadata for detailed chunks\n",
    "    for i, chunk in enumerate(detailed_chunks):\n",
    "        chunk.metadata.update({\n",
    "            \"chunk_id\": i,\n",
    "            \"summary\": False,\n",
    "            \"page\": int(chunk.metadata.get(\"page\", 0))\n",
    "        })\n",
    "\n",
    "    # Create embeddings\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    # Create vector stores asynchronously with rate limit handling\n",
    "    async def create_vectorstore(docs):\n",
    "        \"\"\"\n",
    "        Creates a vector store from a list of documents with rate limit handling.\n",
    "        \n",
    "        Args:\n",
    "            docs: The list of documents to be embedded.\n",
    "            \n",
    "        Returns:\n",
    "            A FAISS vector store containing the embedded documents.\n",
    "        \"\"\"\n",
    "        return await retry_with_exponential_backoff(\n",
    "            asyncio.to_thread(FAISS.from_documents, docs, embeddings)\n",
    "        )\n",
    "\n",
    "    # Generate vector stores for summaries and detailed chunks concurrently\n",
    "    summary_vectorstore, detailed_vectorstore = await asyncio.gather(\n",
    "        create_vectorstore(summaries),\n",
    "        create_vectorstore(detailed_chunks)\n",
    "    )\n",
    "\n",
    "    return summary_vectorstore, detailed_vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the PDF book to both document-level summaries and detailed chunks if the vector stores do not exist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"../vector_stores/summary_store\") and os.path.exists(\"../vector_stores/detailed_store\"):\n",
    "   embeddings = OpenAIEmbeddings()\n",
    "   summary_store = FAISS.load_local(\"../vector_stores/summary_store\", embeddings, allow_dangerous_deserialization=True)\n",
    "   detailed_store = FAISS.load_local(\"../vector_stores/detailed_store\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "else:\n",
    "    summary_store, detailed_store = await encode_pdf_hierarchical(path)\n",
    "    summary_store.save_local(\"../vector_stores/summary_store\")\n",
    "    detailed_store.save_local(\"../vector_stores/detailed_store\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve information according to summary level, and then retrieve information from the chunk level vector store and filter according to the summary level pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_hierarchical(query, summary_vectorstore, detailed_vectorstore, k_summaries=3, k_chunks=5):\n",
    "    \"\"\"\n",
    "    Performs a hierarchical retrieval using the query.\n",
    "\n",
    "    Args:\n",
    "        query: The search query.\n",
    "        summary_vectorstore: The vector store containing document summaries.\n",
    "        detailed_vectorstore: The vector store containing detailed chunks.\n",
    "        k_summaries: The number of top summaries to retrieve.\n",
    "        k_chunks: The number of detailed chunks to retrieve per summary.\n",
    "\n",
    "    Returns:\n",
    "        A list of relevant detailed chunks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve top summaries\n",
    "    top_summaries = summary_vectorstore.similarity_search(query, k=k_summaries)\n",
    "    \n",
    "    relevant_chunks = []\n",
    "    for summary in top_summaries:\n",
    "        # For each summary, retrieve relevant detailed chunks\n",
    "        page_number = summary.metadata[\"page\"]\n",
    "        page_filter = lambda metadata: metadata[\"page\"] == page_number\n",
    "        page_chunks = detailed_vectorstore.similarity_search(\n",
    "            query, \n",
    "            k=k_chunks, \n",
    "            filter=page_filter\n",
    "        )\n",
    "        relevant_chunks.extend(page_chunks)\n",
    "    \n",
    "    return relevant_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate on a use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the greenhouse effect?\"\n",
    "results = retrieve_hierarchical(query, summary_store, detailed_store)\n",
    "\n",
    "# Print results\n",
    "for chunk in results:\n",
    "    print(f\"Page: {chunk.metadata['page']}\")\n",
    "    print(f\"Content: {chunk.page_content}...\")  # Print first 100 characters\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import encode_pdf, encode_from_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\N7\\PycharmProjects\\llm_tasks\\RAG_TECHNIQUES\\.venv\\Lib\\site-packages\\torch\\__init__.py:290: RuntimeWarning: coroutine 'encode_pdf_hierarchical' was never awaited\n",
      "  from torch._C import *  # noqa: F403\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'page'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Create RAG systems\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# baseline_rag = encode_pdf(sample_text, chunk_size=500, chunk_overlap=50)\u001b[39;00m\n\u001b[0;32m     62\u001b[0m baseline_rag \u001b[38;5;241m=\u001b[39m encode_from_string(sample_text, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m---> 63\u001b[0m summary_store, detailed_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m encode_pdf_hierarchical(sample_text, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, is_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Example queries\u001b[39;00m\n\u001b[0;32m     67\u001b[0m queries \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the main types of machine learning?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplain supervised learning and its applications.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow does reinforcement learning differ from other types of machine learning?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     71\u001b[0m ]\n",
      "Cell \u001b[1;32mIn[8], line 59\u001b[0m, in \u001b[0;36mencode_pdf_hierarchical\u001b[1;34m(path, chunk_size, chunk_overlap, is_string)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(documents), batch_size):\n\u001b[0;32m     58\u001b[0m     batch \u001b[38;5;241m=\u001b[39m documents[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\n\u001b[1;32m---> 59\u001b[0m     batch_summaries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m[summarize_doc(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[0;32m     60\u001b[0m     summaries\u001b[38;5;241m.\u001b[39mextend(batch_summaries)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Short pause between batches\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 51\u001b[0m, in \u001b[0;36mencode_pdf_hierarchical.<locals>.summarize_doc\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m     47\u001b[0m summary_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m retry_with_exponential_backoff(summary_chain\u001b[38;5;241m.\u001b[39mainvoke([doc]))\n\u001b[0;32m     48\u001b[0m summary \u001b[38;5;241m=\u001b[39m summary_output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Document(\n\u001b[0;32m     50\u001b[0m     page_content\u001b[38;5;241m=\u001b[39msummary,\n\u001b[1;32m---> 51\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource\u001b[39m\u001b[38;5;124m\"\u001b[39m: path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[0;32m     52\u001b[0m )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'page'"
     ]
    }
   ],
   "source": [
    "# Assuming the previous code for both RAG implementations is already defined\n",
    "\n",
    "# Sample text for the demo\n",
    "sample_text = \"\"\"\n",
    "Chapter 1: Introduction to Machine Learning\n",
    "\n",
    "Machine Learning (ML) is a subset of Artificial Intelligence that focuses on the development of algorithms and statistical models that enable computer systems to improve their performance on a specific task through experience. ML algorithms build a mathematical model based on sample data, known as \"training data,\" in order to make predictions or decisions without being explicitly programmed to perform the task.\n",
    "\n",
    "There are three main types of machine learning:\n",
    "1. Supervised Learning: The algorithm learns from labeled training data.\n",
    "2. Unsupervised Learning: The algorithm learns from unlabeled data.\n",
    "3. Reinforcement Learning: The algorithm learns through interaction with an environment.\n",
    "\n",
    "Chapter 2: Supervised Learning\n",
    "\n",
    "Supervised learning is a type of machine learning where the algorithm learns from labeled training data. In this approach, the algorithm is given a set of input-output pairs and learns to map the input to the output.\n",
    "\n",
    "Common supervised learning algorithms include:\n",
    "- Linear Regression\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Random Forests\n",
    "- Support Vector Machines (SVM)\n",
    "- Neural Networks\n",
    "\n",
    "Applications of supervised learning include image classification, spam detection, and predictive analytics.\n",
    "\n",
    "Chapter 3: Unsupervised Learning\n",
    "\n",
    "Unsupervised learning is a type of machine learning where the algorithm learns patterns from unlabeled data. The goal is to explore the data and find hidden structures within it.\n",
    "\n",
    "Common unsupervised learning algorithms include:\n",
    "- K-means clustering\n",
    "- Hierarchical clustering\n",
    "- Principal Component Analysis (PCA)\n",
    "- Independent Component Analysis (ICA)\n",
    "- Autoencoders\n",
    "\n",
    "Applications of unsupervised learning include anomaly detection, customer segmentation, and dimensionality reduction.\n",
    "\n",
    "Chapter 4: Reinforcement Learning\n",
    "\n",
    "Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives rewards or penalties for its actions and aims to maximize the cumulative reward over time.\n",
    "\n",
    "Key concepts in reinforcement learning include:\n",
    "- States\n",
    "- Actions\n",
    "- Rewards\n",
    "- Policies\n",
    "\n",
    "Common reinforcement learning algorithms include:\n",
    "- Q-Learning\n",
    "- SARSA (State-Action-Reward-State-Action)\n",
    "- Deep Q-Network (DQN)\n",
    "- Policy Gradient Methods\n",
    "\n",
    "Applications of reinforcement learning include game playing (e.g., AlphaGo), robotics, and autonomous vehicles.\n",
    "\"\"\"\n",
    "\n",
    "# Create RAG systems\n",
    "# baseline_rag = encode_pdf(sample_text, chunk_size=500, chunk_overlap=50)\n",
    "baseline_rag = encode_from_string(sample_text, chunk_size=500, chunk_overlap=50)\n",
    "summary_store, detailed_store = await encode_pdf_hierarchical(sample_text, chunk_size=500, chunk_overlap=50, is_string=True)\n",
    "\n",
    "\n",
    "# Example queries\n",
    "queries = [\n",
    "    \"What are the main types of machine learning?\",\n",
    "    \"Explain supervised learning and its applications.\",\n",
    "    \"How does reinforcement learning differ from other types of machine learning?\",\n",
    "]\n",
    "\n",
    "# Function to format and print results\n",
    "def print_results(title, results):\n",
    "    print(f\"\\n{title}\")\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"{i}. {doc.page_content[:150]}...\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Compare results\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    \n",
    "    # Baseline RAG\n",
    "    baseline_results = baseline_rag.similarity_search(query, k=2)\n",
    "    print_results(\"Baseline RAG Results:\", baseline_results)\n",
    "    \n",
    "    # Hierarchical RAG\n",
    "    hierarchical_results = retrieve_hierarchical(query, summary_store, detailed_store, k_summaries=1, k_chunks=2)\n",
    "    print_results(\"Hierarchical RAG Results:\", hierarchical_results)\n",
    "\n",
    "# Analyze and explain the results\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"1. The hierarchical approach generally provides more contextually relevant results.\")\n",
    "print(\"2. For broad questions, the hierarchical method often captures the overall structure better.\")\n",
    "print(\"3. The baseline method might miss important context by focusing on individual chunks.\")\n",
    "print(\"4. The hierarchical approach is particularly effective for queries that span multiple sections or require a broader understanding of the topic.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
