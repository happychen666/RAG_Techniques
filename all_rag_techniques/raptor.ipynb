{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPTOR: Recursive Abstractive Processing and Thematic Organization for Retrieval\n",
    "\n",
    "## Overview\n",
    "RAPTOR is an advanced information retrieval and question-answering system that combines hierarchical document summarization, embedding-based retrieval, and contextual answer generation. It aims to efficiently handle large document collections by creating a multi-level tree of summaries, allowing for both broad and detailed information retrieval.\n",
    "\n",
    "## Motivation\n",
    "Traditional retrieval systems often struggle with large document sets, either missing important details or getting overwhelmed by irrelevant information. RAPTOR addresses this by creating a hierarchical structure of the document collection, allowing it to navigate between high-level concepts and specific details as needed.\n",
    "\n",
    "## Key Components\n",
    "1. **Tree Building**: Creates a hierarchical structure of document summaries.\n",
    "2. **Embedding and Clustering**: Organizes documents and summaries based on semantic similarity.\n",
    "3. **Vectorstore**: Efficiently stores and retrieves document and summary embeddings.\n",
    "4. **Contextual Retriever**: Selects the most relevant information for a given query.\n",
    "5. **Answer Generation**: Produces coherent responses based on retrieved information.\n",
    "\n",
    "## Method Details\n",
    "\n",
    "### Tree Building\n",
    "1. Start with original documents at level 0.\n",
    "2. For each level:\n",
    "   - Embed the texts using a language model.\n",
    "   - Cluster the embeddings (e.g., using Gaussian Mixture Models).\n",
    "   - Generate summaries for each cluster.\n",
    "   - Use these summaries as the texts for the next level.\n",
    "3. Continue until reaching a single summary or a maximum level.\n",
    "\n",
    "### Embedding and Retrieval\n",
    "1. Embed all documents and summaries from all levels of the tree.\n",
    "2. Store these embeddings in a vectorstore (e.g., FAISS) for efficient similarity search.\n",
    "3. For a given query:\n",
    "   - Embed the query.\n",
    "   - Retrieve the most similar documents/summaries from the vectorstore.\n",
    "\n",
    "### Contextual Compression\n",
    "1. Take the retrieved documents/summaries.\n",
    "2. Use a language model to extract only the most relevant parts for the given query.\n",
    "\n",
    "### Answer Generation\n",
    "1. Combine the relevant parts into a context.\n",
    "2. Use a language model to generate an answer based on this context and the original query.\n",
    "\n",
    "## Benefits of this Approach\n",
    "1. **Scalability**: Can handle large document collections by working with summaries at different levels.\n",
    "2. **Flexibility**: Capable of providing both high-level overviews and specific details.\n",
    "3. **Context-Awareness**: Retrieves information from the most appropriate level of abstraction.\n",
    "4. **Efficiency**: Uses embeddings and vectorstore for fast retrieval.\n",
    "5. **Traceability**: Maintains links between summaries and original documents, allowing for source verification.\n",
    "\n",
    "## Conclusion\n",
    "RAPTOR represents a significant advancement in information retrieval and question-answering systems. By combining hierarchical summarization with embedding-based retrieval and contextual answer generation, it offers a powerful and flexible approach to handling large document collections. The system's ability to navigate different levels of abstraction allows it to provide relevant and contextually appropriate answers to a wide range of queries.\n",
    "\n",
    "While RAPTOR shows great promise, future work could focus on optimizing the tree-building process, improving summary quality, and enhancing the retrieval mechanism to better handle complex, multi-faceted queries. Additionally, integrating this approach with other AI technologies could lead to even more sophisticated information processing systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "graph TD\n",
    "    subgraph \"Original Documents\"\n",
    "        D1[Doc1]\n",
    "        D2[Doc2]\n",
    "        D3[Doc3]\n",
    "        D4[Doc4]\n",
    "        D5[Doc5]\n",
    "        D6[Doc6]\n",
    "    end\n",
    "\n",
    "    subgraph \"Level 1 Processing\"\n",
    "        E1[Embedding & Clustering]\n",
    "    end\n",
    "\n",
    "    subgraph \"Level 1 Summaries\"\n",
    "        S1[Summary1]\n",
    "        S2[Summary2]\n",
    "        S3[Summary3]\n",
    "    end\n",
    "\n",
    "    subgraph \"Level 2 Processing\"\n",
    "        E2[Re-embedding & Clustering]\n",
    "    end\n",
    "\n",
    "    subgraph \"Level 2 Summaries\"\n",
    "        S4[Summary4]\n",
    "        S5[Summary5]\n",
    "    end\n",
    "\n",
    "    subgraph \"Level 3 Processing\"\n",
    "        E3[Re-embedding & Clustering]\n",
    "    end\n",
    "\n",
    "    subgraph \"Level 3 Summary\"\n",
    "        S6[Final Summary]\n",
    "    end\n",
    "\n",
    "    %% Connections\n",
    "    D1 & D2 --> E1\n",
    "    D3 & D4 --> E1\n",
    "    D5 & D6 --> E1\n",
    "\n",
    "    E1 --> S1\n",
    "    E1 --> S2\n",
    "    E1 --> S3\n",
    "\n",
    "    S1 & S2 --> E2\n",
    "    S3 --> E2\n",
    "\n",
    "    E2 --> S4\n",
    "    E2 --> S5\n",
    "\n",
    "    S4 & S5 --> E3\n",
    "\n",
    "    E3 --> S6\n",
    "\n",
    "    %% Styling\n",
    "    classDef default fill:#f9f9f9,stroke:#333,stroke-width:2px;\n",
    "    classDef process fill:#FFD700,stroke:#333,stroke-width:2px;\n",
    "    classDef summary fill:#98FB98,stroke:#333,stroke-width:2px;\n",
    "    classDef final fill:#FF6347,stroke:#333,stroke-width:2px;\n",
    "\n",
    "    class E1,E2,E3 process;\n",
    "    class S1,S2,S3,S4,S5 summary;\n",
    "    class S6 final;\n",
    "\n",
    "    %% Labels\n",
    "    S1:::summary\n",
    "    S2:::summary\n",
    "    S3:::summary\n",
    "    S4:::summary\n",
    "    S5:::summary\n",
    "    S6:::final\n",
    "\n",
    "    %% Notes\n",
    "    subgraph \"Notes\"\n",
    "        N1[This process can continue for more levels]\n",
    "        N2[All levels of summaries and original documents are preserved]\n",
    "    end\n",
    "\n",
    "    style N1 fill:#f0f0f0,stroke:#333,stroke-width:1px,stroke-dasharray: 5 5;\n",
    "    style N2 fill:#f0f0f0,stroke:#333,stroke-width:1px,stroke-dasharray: 5 5;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Any\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define logging, llm and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts: List[str]) -> np.ndarray:\n",
    "    \"\"\"Embed texts using OpenAIEmbeddings.\"\"\"\n",
    "    logging.info(f\"Embedding {len(texts)} texts\")\n",
    "    return np.array(embeddings.embed_documents(texts))\n",
    "\n",
    "def perform_clustering(embeddings: np.ndarray, n_clusters: int = 10) -> np.ndarray:\n",
    "    \"\"\"Perform clustering on embeddings using Gaussian Mixture Model.\"\"\"\n",
    "    logging.info(f\"Performing clustering with {n_clusters} clusters\")\n",
    "    gm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "    return gm.fit_predict(embeddings)\n",
    "\n",
    "def summarize_texts(texts: List[str]) -> str:\n",
    "    \"\"\"Summarize a list of texts using OpenAI.\"\"\"\n",
    "    logging.info(f\"Summarizing {len(texts)} texts\")\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Summarize the following text concisely:\\n\\n{text}\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    input_data = {\"text\": texts}\n",
    "    return chain.invoke(input_data)\n",
    "\n",
    "def visualize_clusters(embeddings: np.ndarray, labels: np.ndarray, level: int):\n",
    "    \"\"\"Visualize clusters using PCA.\"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=labels, cmap='viridis')\n",
    "    plt.colorbar(scatter)\n",
    "    plt.title(f'Cluster Visualization - Level {level}')\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAPTOR Core Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_raptor_tree(texts: List[str], max_levels: int = 3) -> Dict[int, pd.DataFrame]:\n",
    "    \"\"\"Build the RAPTOR tree structure with level metadata.\"\"\"\n",
    "    results = {}\n",
    "    current_texts = texts\n",
    "    current_metadata = [{\"level\": 0, \"origin\": \"original\"} for _ in texts]  # Metadata for original documents\n",
    "    \n",
    "    for level in range(1, max_levels + 1):\n",
    "        logging.info(f\"Processing level {level}\")\n",
    "        \n",
    "        # Embed texts\n",
    "        embeddings = embed_texts(current_texts)\n",
    "        \n",
    "        # Perform clustering\n",
    "        n_clusters = min(10, len(current_texts) // 2)\n",
    "        cluster_labels = perform_clustering(embeddings, n_clusters)\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame({\n",
    "            'text': current_texts,\n",
    "            'embedding': list(embeddings),\n",
    "            'cluster': cluster_labels,\n",
    "            'metadata': current_metadata\n",
    "        })\n",
    "        \n",
    "        # Store results\n",
    "        results[level-1] = df  # Store previous level's data\n",
    "        \n",
    "        # Summarize each cluster\n",
    "        summaries = []\n",
    "        new_metadata = []\n",
    "        for cluster in df['cluster'].unique():\n",
    "            cluster_texts = df[df['cluster'] == cluster]['text'].tolist()\n",
    "            cluster_metadata = df[df['cluster'] == cluster]['metadata'].tolist()\n",
    "            summary = summarize_texts(cluster_texts)\n",
    "            summaries.append(summary)\n",
    "            new_metadata.append({\n",
    "                \"level\": level,\n",
    "                \"origin\": f\"summary_of_cluster_{cluster}_level_{level-1}\",\n",
    "                \"child_docs\": cluster_metadata\n",
    "            })\n",
    "        \n",
    "        # Prepare for next level\n",
    "        current_texts = summaries\n",
    "        current_metadata = new_metadata\n",
    "        \n",
    "        # Stop if we have only one summary\n",
    "        if len(current_texts) <= 1:\n",
    "            results[level] = pd.DataFrame({\n",
    "                'text': current_texts,\n",
    "                'embedding': embed_texts(current_texts),\n",
    "                'cluster': [0],\n",
    "                'metadata': current_metadata\n",
    "            })\n",
    "            logging.info(f\"Stopping at level {level} as we have only one summary\")\n",
    "            break\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorstore Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vectorstore(tree_results: Dict[int, pd.DataFrame]) -> FAISS:\n",
    "    \"\"\"Build a FAISS vectorstore from all texts in the RAPTOR tree.\"\"\"\n",
    "    all_texts = []\n",
    "    all_embeddings = []\n",
    "    all_metadatas = []\n",
    "    \n",
    "    for level, df in tree_results.items():\n",
    "        all_texts.extend(df['text'].tolist())\n",
    "        all_embeddings.extend(df['embedding'].tolist())\n",
    "        all_metadatas.extend(df['metadata'].tolist())\n",
    "    \n",
    "    logging.info(f\"Building vectorstore with {len(all_texts)} texts\")\n",
    "    return FAISS.from_embeddings(\n",
    "        list(zip(all_texts, all_embeddings)),\n",
    "        embeddings,\n",
    "        metadatas=all_metadatas\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Retriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_retriever(vectorstore: FAISS) -> ContextualCompressionRetriever:\n",
    "    \"\"\"Create a retriever with contextual compression.\"\"\"\n",
    "    logging.info(\"Creating contextual compression retriever\")\n",
    "    base_retriever = vectorstore.as_retriever()\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Given the following context and question, extract only the relevant information for answering the question:\\n\\n\"\n",
    "        \"Context: {context}\\n\"\n",
    "        \"Question: {question}\\n\\n\"\n",
    "        \"Relevant Information:\"\n",
    "    )\n",
    "    \n",
    "    extractor = LLMChainExtractor.from_llm(llm, prompt=prompt)\n",
    "    \n",
    "    return ContextualCompressionRetriever(\n",
    "        base_compressor=extractor,\n",
    "        base_retriever=base_retriever\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAPTOR Query Process (Online Process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raptor_query(query: str, retriever: ContextualCompressionRetriever) -> Dict[str, Any]:\n",
    "    \"\"\"Process a query using the RAPTOR system with detailed observability.\"\"\"\n",
    "    logging.info(f\"Processing query: {query}\")\n",
    "    \n",
    "    # Retrieve relevant documents\n",
    "    relevant_docs = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    # Prepare detailed information about retrieved documents\n",
    "    doc_details = []\n",
    "    for i, doc in enumerate(relevant_docs, 1):\n",
    "        doc_details.append({\n",
    "            \"index\": i,\n",
    "            \"content\": doc.page_content,\n",
    "            \"metadata\": doc.metadata,\n",
    "            \"similarity_score\": doc.metadata.get('score', 'N/A')\n",
    "        })\n",
    "    \n",
    "    # Generate context from relevant documents\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in relevant_docs])\n",
    "    \n",
    "    # Generate answer\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        \"Given the following context, please answer the question:\\n\\n\"\n",
    "        \"Context: {context}\\n\\n\"\n",
    "        \"Question: {question}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    input_data = {\"context\": context, \"question\": query}\n",
    "    answer = chain.invoke(input_data)\n",
    "    \n",
    "    logging.info(\"Query processing completed\")\n",
    "    \n",
    "    # Prepare the result dictionary with observability data\n",
    "    result = {\n",
    "        \"query\": query,\n",
    "        \"retrieved_documents\": doc_details,\n",
    "        \"num_docs_retrieved\": len(relevant_docs),\n",
    "        \"context_used\": context,\n",
    "        \"answer\": answer,\n",
    "        \"model_used\": llm.model_name,\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def print_query_details(result: Dict[str, Any]):\n",
    "    \"\"\"Print detailed information about the query process, including tree level metadata.\"\"\"\n",
    "    print(f\"Query: {result['query']}\")\n",
    "    print(f\"\\nNumber of documents retrieved: {result['num_docs_retrieved']}\")\n",
    "    print(f\"\\nRetrieved Documents:\")\n",
    "    for doc in result['retrieved_documents']:\n",
    "        print(f\"  Document {doc['index']}:\")\n",
    "        print(f\"    Content: {doc['content'][:100]}...\")  # Show first 100 characters\n",
    "        print(f\"    Similarity Score: {doc['similarity_score']}\")\n",
    "        print(f\"    Tree Level: {doc['metadata'].get('level', 'Unknown')}\")\n",
    "        print(f\"    Origin: {doc['metadata'].get('origin', 'Unknown')}\")\n",
    "        if 'child_docs' in doc['metadata']:\n",
    "            print(f\"    Number of Child Documents: {len(doc['metadata']['child_docs'])}\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"\\nContext used for answer generation:\")\n",
    "    print(result['context_used'])\n",
    "    \n",
    "    print(f\"\\nGenerated Answer:\")\n",
    "    print(result['answer'])\n",
    "    \n",
    "    print(f\"\\nModel Used: {result['model_used']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage and Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(path)\n",
    "documents = loader.load()\n",
    "texts = [doc.page_content for doc in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RAPTOR components instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_results = build_raptor_tree(texts)\n",
    "\n",
    "# Build vectorstore\n",
    "vectorstore = build_vectorstore(tree_results)\n",
    "\n",
    "# Create retriever\n",
    "retriever = create_retriever(vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a query and observe where it got the data from + results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pipeline\n",
    "query = \"What is the greenhouse effect?\"\n",
    "result = raptor_query(query, retriever)\n",
    "print_query_details(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
