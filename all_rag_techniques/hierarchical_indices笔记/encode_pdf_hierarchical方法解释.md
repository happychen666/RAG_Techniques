è¿™æ®µä»£ç æ˜¯ä¸€ä¸ªç”¨äºå°† **PDF æ–‡ä»¶å¼‚æ­¥å¤„ç†æˆä¸¤ä¸ªåˆ†å±‚å‘é‡åº“ï¼ˆsummary + chunksï¼‰** çš„å‡½æ•°ï¼Œç›®çš„æ˜¯è®©åç»­çš„é—®ç­”ã€æ£€ç´¢æ›´åŠ é«˜æ•ˆã€‚æˆ‘ä»¬é€è¡Œè¯¦ç»†è®²è§£ï¼Œå¹¶ç»“åˆæ•°å€¼ä¾‹å­è¯´æ˜å®ƒçš„æ ¸å¿ƒåŠŸèƒ½ã€‚

---

## ğŸš€ ä¸€å¥è¯æ€»ç»“åŠŸèƒ½ï¼š

> æŠŠä¸€ä¸ª PDF æ–‡ä»¶â€œåˆ‡ç‰‡â€ã€â€œæ‘˜è¦â€ï¼Œç„¶ååˆ†åˆ«ç”¨ OpenAI çš„ Embedding ç¼–ç ï¼Œåˆ›å»ºä¸¤ä¸ª FAISS å‘é‡åº“ï¼šä¸€ä¸ªæ˜¯ **æ‘˜è¦çº§ï¼ˆsummaryï¼‰å‘é‡åº“**ï¼Œä¸€ä¸ªæ˜¯ **ç»†èŠ‚çº§ï¼ˆchunkï¼‰å‘é‡åº“**ï¼Œæ–¹ä¾¿åç»­é—®ç­”ç³»ç»ŸæŒ‰éœ€åŒ¹é…ä¸Šä¸‹æ–‡ã€‚

---

## âœ… å‡½æ•°å®šä¹‰éƒ¨åˆ†

```python
async def encode_pdf_hierarchical(path, chunk_size=1000, chunk_overlap=200, is_string=False):
```

* `path`: PDF æ–‡ä»¶è·¯å¾„ï¼Œæˆ–è€…ç›´æ¥ä¼ æ–‡æœ¬ï¼ˆ`is_string=True` æ—¶ï¼‰ã€‚
* `chunk_size`: æ¯æ®µæ–‡æœ¬æœ€å¤§å­—ç¬¦æ•°ï¼Œæ¯”å¦‚è®¾æˆ `1000`ã€‚
* `chunk_overlap`: ç›¸é‚» chunk é‡å çš„å­—ç¬¦æ•°ï¼Œæ¯”å¦‚ `200`ã€‚
* `is_string`: å¦‚æœä¼ çš„æ˜¯çº¯æ–‡æœ¬è€Œä¸æ˜¯ PDF æ–‡ä»¶ï¼Œå°±è®¾ä¸º Trueã€‚

---

## ğŸ“˜ ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ–‡æ¡£

```python
if not is_string:
    loader = PyPDFLoader(path)
    documents = await asyncio.to_thread(loader.load)
else:
    ...
```

* å¦‚æœæ˜¯ PDFï¼Œä½¿ç”¨ `PyPDFLoader` å¼‚æ­¥åŠ è½½ï¼ˆé¿å…é˜»å¡ï¼‰ã€‚
* å¦‚æœæ˜¯çº¯å­—ç¬¦ä¸²ï¼Œå°±ç”¨ `RecursiveCharacterTextSplitter` æŒ‰ `chunk_size=1000` å’Œ `chunk_overlap=200` æ¥åˆ‡åˆ†ã€‚

ğŸ§  **ä¸¾ä¸ªä¾‹å­ï¼š**

å‡è®¾ä½ ä¼ å…¥çš„æ˜¯ä¸€ä¸ª PDFï¼Œæœ‰ 10 é¡µå†…å®¹ï¼Œæ¯é¡µ 3000 ä¸ªå­—ç¬¦ï¼Œæ€»å…± 30,000 å­—ç¬¦ã€‚

---

## âœ‚ï¸ ç¬¬äºŒæ­¥ï¼šæŒ‰é¡µç”Ÿæˆæ‘˜è¦ summaryï¼ˆdocument-levelï¼‰

```python
summary_llm = ChatOpenAI(model_name="gpt-4o-mini")
summary_chain = load_summarize_chain(summary_llm, chain_type="map_reduce")
```

è¿™é‡Œå®šä¹‰äº†ä¸€ä¸ª OpenAI çš„ GPT-4o-mini æ¨¡å‹ï¼Œç”¨äºæ‘˜è¦ã€‚

ç„¶åæœ‰ä¸€ä¸ªå‡½æ•°ï¼š

```python
async def summarize_doc(doc):
    ...
```

è¿™æ˜¯å¯¹å•é¡µæ–‡æ¡£è¿›è¡Œæ‘˜è¦ã€‚å®ƒåšäº†ä»¥ä¸‹æ“ä½œï¼š

* ç”¨ `summary_chain.ainvoke([doc])` æ¥è°ƒç”¨ LLM æ¨¡å‹ï¼›
* è¿”å›ä¸€ä¸ªæ–°çš„ `Document` å¯¹è±¡ï¼ŒåŒ…å«ï¼š

  * æ‘˜è¦åçš„æ–‡æœ¬ï¼›
  * åŸæ–‡çš„é¡µç ã€æ¥æºã€æ˜¯å¦ä¸ºæ‘˜è¦æ ‡å¿—ã€‚

ç„¶åç”¨ï¼š

```python
for i in range(0, len(documents), batch_size):
    ...
```

æŠŠæ‰€æœ‰æ–‡æ¡£åˆ†æ‰¹ï¼ˆæ¯æ¬¡ 5 ä¸ªï¼‰å¹¶å‘æ‰§è¡Œæ‘˜è¦ï¼Œé¿å…è§¦å‘ OpenAI çš„ rate limitã€‚

ğŸ§  **ä¾‹å­ï¼š**

å‡è®¾ä½ æœ‰ 10 é¡µå†…å®¹ï¼Œç³»ç»Ÿä¼šç”Ÿæˆ 10 ä¸ªæ‘˜è¦ï¼Œæ¯ä¸ªæ‘˜è¦å¤§æ¦‚ 300ï½500 å­—ï¼ˆè§†ä½ è®¾ç½®çš„ `max_tokens=4000` è€Œå®šï¼‰ã€‚

---

## ğŸ”ª ç¬¬ä¸‰æ­¥ï¼šåˆ‡æˆæ›´å°å—ï¼ˆchunk-levelï¼‰

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=chunk_size, chunk_overlap=chunk_overlap
)
detailed_chunks = await asyncio.to_thread(text_splitter.split_documents, documents)
```

è¿™ä¸€æ­¥æ˜¯æ›´ç»†èŠ‚çš„åˆ‡å‰²ï¼Œæ¯”å¦‚ï¼š

* ä½ ä¸€é¡µåŸå§‹ PDF æ˜¯ 3000 å­—ï¼›
* `chunk_size=1000`, `chunk_overlap=200`ï¼›
* é‚£æ¯ä¸€é¡µå°±ä¼šè¢«åˆ‡æˆ 3 ä¸ª chunkï¼š

  * ç¬¬ä¸€ä¸ªï¼šç¬¬ 0-1000 å­—ç¬¦ï¼›
  * ç¬¬äºŒä¸ªï¼šç¬¬ 800-1800ï¼›
  * ç¬¬ä¸‰ä¸ªï¼š1600-2600ï¼›â€¦

ä¹Ÿå°±æ˜¯è®©æ¨¡å‹èƒ½å¯¹æ›´å°ç²’åº¦çš„å†…å®¹è¿›è¡Œæ£€ç´¢ã€‚

æ¯ä¸ª chunk ä¼šé™„ä¸Š metadataï¼Œå¦‚ï¼š

```python
chunk.metadata.update({
    "chunk_id": i,
    "summary": False,
    "page": int(chunk.metadata.get("page", 0))
})
```

---

## ğŸ§  ç¬¬å››æ­¥ï¼šç¼–ç æˆå‘é‡å¹¶åˆ›å»ºå‘é‡åº“

é¦–å…ˆå®šä¹‰ embeddingï¼š

```python
embeddings = OpenAIEmbeddings()
```

ç„¶åå®šä¹‰å‘é‡åº“åˆ›å»ºå‡½æ•°ï¼ˆå¸¦ retryï¼‰ï¼š

```python
async def create_vectorstore(docs):
    return await retry_with_exponential_backoff(
        asyncio.to_thread(FAISS.from_documents, docs, embeddings)
    )
```

æ¥ç€å¹¶å‘åˆ›å»ºä¸¤ä¸ª FAISS å‘é‡åº“ï¼š

```python
summary_vectorstore, detailed_vectorstore = await asyncio.gather(
    create_vectorstore(summaries),
    create_vectorstore(detailed_chunks)
)
```

### ğŸ“Œ FAISS æ˜¯ä»€ä¹ˆï¼Ÿ

æ˜¯ä¸€ä¸ª Facebook å¼€æºçš„é«˜æ•ˆå‘é‡æ£€ç´¢åº“ï¼Œå¯ä»¥ç”¨äºç›¸ä¼¼å†…å®¹æœç´¢ã€‚

---

## ğŸ”š æœ€åè¿”å›ä¸¤ä¸ªå‘é‡åº“

```python
return summary_vectorstore, detailed_vectorstore
```

---

## ğŸ“Š æ•´ä½“æµç¨‹æ€»ç»“å›¾ç¤º

| æ­¥éª¤           | æ•°æ®å½¢æ€             | ç¤ºä¾‹æ•°é‡            | è¯´æ˜                 |
| ------------ | ---------------- | --------------- | ------------------ |
| åŠ è½½ PDF       | 10 é¡µ Document    | 10 ä¸ª            | æ¯é¡µä¸€ä¸ª Document å¯¹è±¡   |
| æ‘˜è¦ç”Ÿæˆ         | æ–‡æœ¬æ‘˜è¦ Document    | 10 ä¸ª            | æ¯é¡µç”Ÿæˆä¸€ä¸ªç®€æ´æ‘˜è¦         |
| æ–‡æœ¬åˆ‡å—         | Chunk çº§ Document | çº¦ 30 ä¸ª          | æ¯é¡µåˆ‡æˆ 3 ä¸ª chunk     |
| Embedding ç¼–ç  | å‘é‡è¡¨ç¤º             | summary + chunk | ç”¨äºå‘é‡æ£€ç´¢             |
| å‘é‡åº“          | FAISS Index      | 2 ä¸ª             | ä¸€ä¸ªæ˜¯æ‘˜è¦åº“ï¼Œä¸€ä¸ªæ˜¯ chunk åº“ |

---

## ğŸ§ª ä¸¾ä¸ªçœŸå®æ•°å€¼ä¾‹å­

å¦‚æœä½ ä¼ å…¥ä¸€ä¸ª PDF æ–‡ä»¶ã€Šäººå·¥æ™ºèƒ½å…¥é—¨.pdfã€‹ï¼Œ10 é¡µå†…å®¹ï¼š

* æ¯é¡µå¹³å‡ 3000 å­—ï¼›
* `chunk_size=1000`, `chunk_overlap=200`ï¼›

ä½ å°†å¾—åˆ°ï¼š

| ç±»å‹       | æ•°é‡     | è¯´æ˜                 |
| -------- | ------ | ------------------ |
| é¡µçº§æ–‡æ¡£     | 10 ä¸ª   | ç”¨äºæ‘˜è¦               |
| é¡µçº§æ‘˜è¦     | 10 ä¸ª   | æ¯é¡µç”Ÿæˆä¸€æ¬¡æ‘˜è¦           |
| Chunk æ–‡æ¡£ | çº¦ 30 ä¸ª | æ¯é¡µåˆ‡æˆ 3 å—           |
| å‘é‡åº“      | 2 ä¸ª    | summaries + chunks |

---

## ğŸ” retry\_with\_exponential\_backoff æ˜¯å¹²å˜›çš„ï¼Ÿ

è¿™ä¸ªå‡½æ•°è´Ÿè´£å¤„ç† API è°ƒç”¨æ—¶å‡ºç° **RateLimitError** æˆ– **Timeout** ç­‰æƒ…å†µï¼Œè‡ªåŠ¨é‡è¯•ã€æŒ‡æ•°å›é€€ï¼Œé¿å…æ•´ä¸ªæµç¨‹å´©æ‰ã€‚

---

## âœ… åº”ç”¨åœºæ™¯

* âœ… åŒ»ç–—çŸ¥è¯†åº“ï¼šåŒ»ç”Ÿä¸Šä¼ ä¸´åºŠæŒ‡å— PDFï¼Œæ„å»ºæ‘˜è¦ + è¯¦ç»†å†…å®¹æ£€ç´¢åº“ã€‚
* âœ… æ•™æçŸ¥è¯†åº“ï¼šå­¦ç”Ÿä¸Šä¼ æ•™æ PDFï¼Œå¿«é€Ÿé—®ç­”å¯ä»¥å…ˆæŸ¥æ‘˜è¦ï¼Œå†æŸ¥ç»†èŠ‚ã€‚
* âœ… æ³•å¾‹æ–‡ä»¶è§£æï¼šä¸Šä¼ åˆåŒï¼Œå…ˆè¯»æ•´ä½“ï¼Œå†æ‰¾ç»†èŠ‚ã€‚

---

å¦‚æœä½ éœ€è¦æˆ‘æ¼”ç¤ºè¿™ä¸ªå‡½æ•°åœ¨ä½ æœ¬åœ°å¦‚ä½•è¿è¡Œï¼Œæˆ–å†™ä¸€ä¸ªç®€å•çš„æµ‹è¯•ä¾‹å­ï¼Œæˆ‘ä¹Ÿå¯ä»¥å¸®ä½ ç»§ç»­æ‰©å±•ã€‚æ˜¯å¦éœ€è¦ï¼Ÿ
