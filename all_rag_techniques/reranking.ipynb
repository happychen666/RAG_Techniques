{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reranking Methods in RAG Systems\n",
        "\n",
        "## Overview\n",
        "Reranking is a crucial step in Retrieval-Augmented Generation (RAG) systems that aims to improve the relevance and quality of retrieved documents. It involves reassessing and reordering initially retrieved documents to ensure that the most pertinent information is prioritized for subsequent processing or presentation.\n",
        "\n",
        "## Motivation\n",
        "The primary motivation for reranking in RAG systems is to overcome limitations of initial retrieval methods, which often rely on simpler similarity metrics. Reranking allows for more sophisticated relevance assessment, taking into account nuanced relationships between queries and documents that might be missed by traditional retrieval techniques. This process aims to enhance the overall performance of RAG systems by ensuring that the most relevant information is used in the generation phase.\n",
        "\n",
        "## Key Components\n",
        "Reranking systems typically include the following components:\n",
        "\n",
        "1. Initial Retriever: Often a vector store using embedding-based similarity search.\n",
        "2. Reranking Model: This can be either:\n",
        "   - A Large Language Model (LLM) for scoring relevance\n",
        "   - A Cross-Encoder model specifically trained for relevance assessment\n",
        "3. Scoring Mechanism: A method to assign relevance scores to documents\n",
        "4. Sorting and Selection Logic: To reorder documents based on new scores\n",
        "\n",
        "## Method Details\n",
        "The reranking process generally follows these steps:\n",
        "\n",
        "1. Initial Retrieval: Fetch an initial set of potentially relevant documents.\n",
        "2. Pair Creation: Form query-document pairs for each retrieved document.\n",
        "3. Scoring: \n",
        "   - LLM Method: Use prompts to ask the LLM to rate document relevance.\n",
        "   - Cross-Encoder Method: Feed query-document pairs directly into the model.\n",
        "4. Score Interpretation: Parse and normalize the relevance scores.\n",
        "5. Reordering: Sort documents based on their new relevance scores.\n",
        "6. Selection: Choose the top K documents from the reordered list.\n",
        "\n",
        "## Benefits of this Approach\n",
        "Reranking offers several advantages:\n",
        "\n",
        "1. Improved Relevance: By using more sophisticated models, reranking can capture subtle relevance factors.\n",
        "2. Flexibility: Different reranking methods can be applied based on specific needs and resources.\n",
        "3. Enhanced Context Quality: Providing more relevant documents to the RAG system improves the quality of generated responses.\n",
        "4. Reduced Noise: Reranking helps filter out less relevant information, focusing on the most pertinent content.\n",
        "\n",
        "## Conclusion\n",
        "Reranking is a powerful technique in RAG systems that significantly enhances the quality of retrieved information. Whether using LLM-based scoring or specialized Cross-Encoder models, reranking allows for more nuanced and accurate assessment of document relevance. This improved relevance translates directly to better performance in downstream tasks, making reranking an essential component in advanced RAG implementations.\n",
        "\n",
        "The choice between LLM-based and Cross-Encoder reranking methods depends on factors such as required accuracy, available computational resources, and specific application needs. Both approaches offer substantial improvements over basic retrieval methods and contribute to the overall effectiveness of RAG systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "\n",
        "<img src=\"../images/reranking-visualization.svg\" alt=\"rerank llm\" style=\"width:100%; height:auto;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "\n",
        "<img src=\"../images/reranking_comparison.svg\" alt=\"rerank llm\" style=\"width:100%; height:auto;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Package Installation and Imports\n",
        "\n",
        "The cell below installs all necessary packages required to run this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not install packages due to an OSError: [WinError 32] 另一个程序正在使用此文件，进程无法访问。: 'D:\\\\AppGallery\\\\anaconda\\\\envs\\\\RAG_Techniques\\\\Lib\\\\site-packages\\\\sentence_transformers\\\\cross_encoder\\\\CrossEncoder.py'\n",
            "Consider using the `--user` option or check the permissions.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting langchain-openai\n",
            "  Using cached langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: python-dotenv in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (1.1.1)\n",
            "Collecting sentence-transformers\n",
            "  Using cached sentence_transformers-5.0.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Using cached langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
            "  Using cached langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting langsmith>=0.1.17 (from langchain)\n",
            "  Using cached langsmith-0.4.9-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Collecting openai<2.0.0,>=1.86.0 (from langchain-openai)\n",
            "  Using cached openai-1.98.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Using cached tiktoken-0.9.0-cp313-cp313-win_amd64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.86.0->langchain-openai)\n",
            "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.86.0->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2025.7.34)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Using cached transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
            "Requirement already satisfied: torch>=1.11.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from sentence-transformers) (2.7.1)\n",
            "Collecting scikit-learn (from sentence-transformers)\n",
            "  Using cached scikit_learn-1.7.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from sentence-transformers) (1.16.1)\n",
            "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
            "  Using cached huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: Pillow in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: filelock in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.2)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: setuptools in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (78.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: colorama in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.86.0->langchain-openai) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Using cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
            "Using cached langchain_core-0.3.72-py3-none-any.whl (442 kB)\n",
            "Using cached langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
            "Using cached langchain_openai-0.3.28-py3-none-any.whl (70 kB)\n",
            "Using cached openai-1.98.0-py3-none-any.whl (767 kB)\n",
            "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "Using cached tiktoken-0.9.0-cp313-cp313-win_amd64.whl (894 kB)\n",
            "Using cached sentence_transformers-5.0.0-py3-none-any.whl (470 kB)\n",
            "Using cached transformers-4.54.1-py3-none-any.whl (11.2 MB)\n",
            "Using cached huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
            "Using cached tokenizers-0.21.4-cp39-abi3-win_amd64.whl (2.5 MB)\n",
            "Using cached langsmith-0.4.9-py3-none-any.whl (369 kB)\n",
            "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Using cached scikit_learn-1.7.1-cp313-cp313-win_amd64.whl (8.7 MB)\n",
            "Installing collected packages: tiktoken, scikit-learn, requests-toolbelt, huggingface-hub, httpx, tokenizers, openai, langsmith, transformers, langchain-core, sentence-transformers, langchain-text-splitters, langchain-openai, langchain\n",
            "\n",
            "   ----------------------------------------  0/14 [tiktoken]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   -- -------------------------------------  1/14 [scikit-learn]\n",
            "   ----- ----------------------------------  2/14 [requests-toolbelt]\n",
            "   ----- ----------------------------------  2/14 [requests-toolbelt]\n",
            "   ----- ----------------------------------  2/14 [requests-toolbelt]\n",
            "   ----- ----------------------------------  2/14 [requests-toolbelt]\n",
            "   ----- ----------------------------------  2/14 [requests-toolbelt]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   -------- -------------------------------  3/14 [huggingface-hub]\n",
            "   ----------- ----------------------------  4/14 [httpx]\n",
            "   ----------- ----------------------------  4/14 [httpx]\n",
            "   ----------- ----------------------------  4/14 [httpx]\n",
            "   ----------- ----------------------------  4/14 [httpx]\n",
            "   ----------- ----------------------------  4/14 [httpx]\n",
            "   -------------- -------------------------  5/14 [tokenizers]\n",
            "   -------------- -------------------------  5/14 [tokenizers]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   ----------------- ----------------------  6/14 [openai]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   -------------------- -------------------  7/14 [langsmith]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ---------------------- -----------------  8/14 [transformers]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ------------------------- --------------  9/14 [langchain-core]\n",
            "   ---------------------------- ----------- 10/14 [sentence-transformers]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install required packages \n",
        "!pip install langchain langchain-openai python-dotenv sentence-transformers langchain_community rank_bm25  pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pymupdf\n",
            "  Using cached pymupdf-1.26.3-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
            "Collecting asyncio\n",
            "  Using cached asyncio-3.4.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in d:\\appgallery\\anaconda\\envs\\rag_techniques\\lib\\site-packages (2.3.2)\n",
            "Collecting enum\n",
            "  Using cached enum-0.4.7.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'error'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × python setup.py egg_info did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [8 lines of output]\n",
            "      Traceback (most recent call last):\n",
            "        File \"<string>\", line 2, in <module>\n",
            "        File \"<pip-setuptools-caller>\", line 11, in <module>\n",
            "        File \"D:\\AppGallery\\anaconda\\envs\\RAG_Techniques\\Lib\\tokenize.py\", line 33, in <module>\n",
            "          import re\n",
            "        File \"D:\\AppGallery\\anaconda\\envs\\RAG_Techniques\\Lib\\re\\__init__.py\", line 142, in <module>\n",
            "          @enum.global_enum\n",
            "      AttributeError: module 'enum' has no attribute 'global_enum' (consider renaming 'C:\\Users\\26954\\AppData\\Local\\Temp\\pip-install-qz6znypm\\enum_5b48d9b033fa4ef7b60c06fb8ffa1f75\\enum.py' since it has the same name as the standard library module named 'enum' and prevents importing that standard library module)\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "error: metadata-generation-failed\n",
            "\n",
            "× Encountered error while generating package metadata.\n",
            "╰─> See above for output.\n",
            "\n",
            "note: This is an issue with the package mentioned above, not pip.\n",
            "hint: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf asyncio numpy enum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone the repository to access helper functions and evaluation modules\n",
        "# !git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git\n",
        "\n",
        "#把这个新下载的文件夹 RAG_TECHNIQUES 加入到 Python 的模块搜索路径。\n",
        "# import sys\n",
        "# sys.path.append('RAG_TECHNIQUES')\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../\")\n",
        "# If you need to run with the latest data\n",
        "# !cp -r RAG_TECHNIQUES/data ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from dotenv import load_dotenv\n",
        "from langchain.docstore.document import Document\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "\n",
        "# Original path append replaced for Colab compatibility\n",
        "from helper_functions import *\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Set the OpenAI API key environment variable\n",
        "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the document's path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download required data files\n",
        "import os\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Download the PDF document used in this notebook\n",
        "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
        "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = \"../data/Understanding_Climate_Change.pdf\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorstore = encode_pdf(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 1: LLM based function to rerank the retrieved documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "\n",
        "<img src=\"../images/rerank_llm.svg\" alt=\"rerank llm\" style=\"width:40%; height:auto;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a custom reranking function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RatingScore(BaseModel):\n",
        "    relevance_score: float = Field(..., description=\"The relevance score of a document to a query.\")\n",
        "\n",
        "def rerank_documents(query: str, docs: List[Document], top_n: int = 3) -> List[Document]:\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"query\", \"doc\"],\n",
        "        template=\"\"\"On a scale of 1-10, rate the relevance of the following document to the query. Consider the specific context and intent of the query, not just keyword matches.\n",
        "        Query: {query}\n",
        "        Document: {doc}\n",
        "        Relevance Score:\"\"\"\n",
        "    )\n",
        "    \n",
        "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
        "    llm_chain = prompt_template | llm.with_structured_output(RatingScore)\n",
        "    \n",
        "    scored_docs = []\n",
        "    for doc in docs:\n",
        "        input_data = {\"query\": query, \"doc\": doc.page_content}\n",
        "        score = llm_chain.invoke(input_data).relevance_score\n",
        "        try:\n",
        "            score = float(score)\n",
        "        except ValueError:\n",
        "            score = 0  # Default score if parsing fails\n",
        "        scored_docs.append((doc, score))\n",
        "    \n",
        "    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
        "    return [doc for doc, _ in reranked_docs[:top_n]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example usage of the reranking function with a sample query relevant to the document\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\AppGallery\\anaconda\\envs\\RAG_Techniques\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top initial documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "goals. Policies should promote synergies between biodiversity conservation and climate \n",
            "action. \n",
            "Chapter 10: Climate Change and Human Health \n",
            "Health Impacts \n",
            "Heat-Related Illnesses \n",
            "Rising temperature...\n",
            "\n",
            "Document 3:\n",
            "managed retreats. \n",
            "Extreme Weather Events \n",
            "Climate change is linked to an increase in the frequency and severity of extreme weather \n",
            "events, such as hurricanes, heatwaves, droughts, and heavy rainfall...\n",
            "Query: What are the impacts of climate change on biodiversity?\n",
            "\n",
            "Top reranked documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "cultural perceptions. \n",
            "Youth Engagement \n",
            "Youth are vital stakeholders in climate action. Empowering young people through education, \n",
            "activism, and leadership opportunities can drive transformative cha...\n",
            "\n",
            "Document 3:\n",
            "Coral reefs are highly sensitive to changes in temperature and acidity. Ocean acidification \n",
            "and warming waters contribute to coral bleaching and mortality, threatening biodiversity and \n",
            "fisheries. Pr...\n"
          ]
        }
      ],
      "source": [
        "query = \"What are the impacts of climate change on biodiversity?\"\n",
        "initial_docs = vectorstore.similarity_search(query, k=15)\n",
        "reranked_docs = rerank_documents(query, initial_docs)\n",
        "\n",
        "# print first 3 initial documents\n",
        "print(\"Top initial documents:\")\n",
        "for i, doc in enumerate(initial_docs[:3]):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document\n",
        "\n",
        "\n",
        "# Print results\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(\"Top reranked documents:\")\n",
        "for i, doc in enumerate(reranked_docs):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a custom retriever based on our reranker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\26954\\AppData\\Local\\Temp\\ipykernel_8500\\1743993545.py:2: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
            "  class CustomRetriever(BaseRetriever):\n"
          ]
        }
      ],
      "source": [
        "# Create a custom retriever class\n",
        "class CustomRetriever(BaseRetriever):\n",
        "    \n",
        "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n",
        "        initial_docs = self.vectorstore.similarity_search(query, k=30)\n",
        "        return rerank_documents(query, initial_docs, top_n=num_docs)\n",
        "\n",
        "\n",
        "# Create the custom retriever\n",
        "custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
        "\n",
        "# Create an LLM for answering questions\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "# Create the RetrievalQA chain with the custom retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=custom_retriever,\n",
        "    return_source_documents=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\26954\\AppData\\Local\\Temp\\ipykernel_8500\\546735038.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = qa_chain({\"query\": query})\n",
            "d:\\AppGallery\\anaconda\\envs\\RAG_Techniques\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question: What are the impacts of climate change on biodiversity?\n",
            "Answer: Climate change impacts biodiversity by shifting habitat ranges, changing species distributions, and disrupting ecosystem functions. In terrestrial ecosystems, such changes can lead to a loss of biodiversity and disrupt ecological balance as forests, grasslands, and deserts experience shifts in plant and animal species composition. Marine ecosystems are particularly vulnerable, as rising sea temperatures, ocean acidification, and changing currents affect marine biodiversity, disrupting marine food webs and fisheries. Overall, these shifts can lead to habitat loss and contribute to species extinction.\n",
            "\n",
            "Relevant source documents:\n",
            "\n",
            "Document 1:\n",
            "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
            "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
            "experiencing shi...\n",
            "\n",
            "Document 2:\n",
            "Tropical rainforests are particularly important for carbon storage. Deforestation in the \n",
            "Amazon, Congo Basin, and Southeast Asia has significant impacts on global carbon cycles \n",
            "and biodiversity. The...\n"
          ]
        }
      ],
      "source": [
        "result = qa_chain({\"query\": query})\n",
        "\n",
        "print(f\"\\nQuestion: {query}\")\n",
        "print(f\"Answer: {result['result']}\")\n",
        "print(\"\\nRelevant source documents:\")\n",
        "for i, doc in enumerate(result[\"source_documents\"]):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example that demonstrates why we should use reranking "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Comparison of Retrieval Techniques\n",
            "==================================\n",
            "Query: what is the capital of france?\n",
            "\n",
            "Baseline Retrieval Result:\n",
            "\n",
            "Document 1:\n",
            "The capital of France is great.\n",
            "\n",
            "Document 2:\n",
            "The capital of France is beautiful.\n",
            "\n",
            "Advanced Retrieval Result:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\26954\\AppData\\Local\\Temp\\ipykernel_8500\\3086860992.py:28: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  advanced_docs = custom_retriever.get_relevant_documents(query)\n",
            "d:\\AppGallery\\anaconda\\envs\\RAG_Techniques\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:1844: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Document 1:\n",
            "Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower. \n",
            "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\n",
            "\n",
            "Document 2:\n",
            "The capital of France is great.\n"
          ]
        }
      ],
      "source": [
        "chunks = [\n",
        "    \"The capital of France is great.\",\n",
        "    \"The capital of France is huge.\",\n",
        "    \"The capital of France is beautiful.\",\n",
        "    \"\"\"Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower. \n",
        "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\"\"\", \n",
        "    \"I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\"\n",
        "]\n",
        "docs = [Document(page_content=sentence) for sentence in chunks]\n",
        "\n",
        "\n",
        "def compare_rag_techniques(query: str, docs: List[Document] = docs) -> None:\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "    print(\"Comparison of Retrieval Techniques\")\n",
        "    print(\"==================================\")\n",
        "    print(f\"Query: {query}\\n\")\n",
        "    \n",
        "    print(\"Baseline Retrieval Result:\")\n",
        "    baseline_docs = vectorstore.similarity_search(query, k=2)\n",
        "    for i, doc in enumerate(baseline_docs):\n",
        "        print(f\"\\nDocument {i+1}:\")\n",
        "        print(doc.page_content)\n",
        "\n",
        "    print(\"\\nAdvanced Retrieval Result:\")\n",
        "    custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
        "    advanced_docs = custom_retriever.get_relevant_documents(query)\n",
        "    for i, doc in enumerate(advanced_docs):\n",
        "        print(f\"\\nDocument {i+1}:\")\n",
        "        print(doc.page_content)\n",
        "\n",
        "\n",
        "query = \"what is the capital of france?\"\n",
        "compare_rag_techniques(query, docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Method 2: Cross Encoder models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"text-align: center;\">\n",
        "\n",
        "<img src=\"../images/rerank_cross_encoder.svg\" alt=\"rerank cross encoder\" style=\"width:40%; height:auto;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Define the cross encoder class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
        "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
        "    cross_encoder: Any = Field(description=\"Cross-encoder model for reranking\")\n",
        "    k: int = Field(default=5, description=\"Number of documents to retrieve initially\")\n",
        "    rerank_top_k: int = Field(default=3, description=\"Number of documents to return after reranking\")\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        # Initial retrieval\n",
        "        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n",
        "        \n",
        "        # Prepare pairs for cross-encoder\n",
        "        pairs = [[query, doc.page_content] for doc in initial_docs]\n",
        "        \n",
        "        # Get cross-encoder scores\n",
        "        scores = self.cross_encoder.predict(pairs)\n",
        "        \n",
        "        # Sort documents by score\n",
        "        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
        "        \n",
        "        # Return top reranked documents\n",
        "        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]\n",
        "\n",
        "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
        "        raise NotImplementedError(\"Async retrieval not implemented\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create an instance and showcase over an example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the cross-encoder retriever\n",
        "cross_encoder_retriever = CrossEncoderRetriever(\n",
        "    vectorstore=vectorstore,\n",
        "    cross_encoder=cross_encoder,\n",
        "    k=10,  # Retrieve 10 documents initially\n",
        "    rerank_top_k=5  # Return top 5 after reranking\n",
        ")\n",
        "\n",
        "# Set up the LLM\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
        "\n",
        "# Create the RetrievalQA chain with the cross-encoder retriever\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=cross_encoder_retriever,\n",
        "    return_source_documents=True\n",
        ")\n",
        "\n",
        "# Example query\n",
        "query = \"What are the impacts of climate change on biodiversity?\"\n",
        "result = qa_chain({\"query\": query})\n",
        "\n",
        "print(f\"\\nQuestion: {query}\")\n",
        "print(f\"Answer: {result['result']}\")\n",
        "print(\"\\nRelevant source documents:\")\n",
        "for i, doc in enumerate(result[\"source_documents\"]):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=all-rag-techniques--reranking)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "RAG_Techniques",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
